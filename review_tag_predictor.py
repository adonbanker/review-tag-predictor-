# -*- coding: utf-8 -*-
"""review-tag-predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iX-1AHRhZxg22S3cTGU9ynJgAuuBgjVz
"""
import nltk
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')

import requests
import pandas as pd
import time
import re
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import f1_score

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

headers = {
    "X-RapidAPI-Key": "5661a6fd14mshf84b2420bbee2b0p178ea5jsnf730fdf5e8ef",
    "X-RapidAPI-Host": "local-business-data.p.rapidapi.com"
}

params = {
    "query": "coffee shop",
    "lat": "40.730610",
    "lng": "-73.935242",
    "radius": "1000",
    "limit": "5",
    "language": "en",
    "zoom": "14"
}

url = "https://local-business-data.p.rapidapi.com/search-in-area"
response = requests.get(url, headers=headers, params=params)

if response.status_code == 200:
    data = response.json()
    location_df = pd.DataFrame(data.get("data", []))
else:
    print("Failed to fetch location data")

all_reviews_df = pd.DataFrame()

if not location_df.empty and 'business_id' in location_df.columns:
    for business_id in location_df['business_id']:
        r = requests.get(
            "https://local-business-data.p.rapidapi.com/business-reviews",
            headers=headers,
            params={"business_id": business_id}
        )
        if r.status_code == 200:
            temp = pd.DataFrame(r.json().get("data", []))
            all_reviews_df = pd.concat([all_reviews_df, temp], ignore_index=True)
        time.sleep(1)

stop_words = set(stopwords.words('english'))

def clean_text(text):
    if isinstance(text, str):
        text = re.sub(r'<.*?>', '', text)
        text = re.sub(r'[^a-zA-Z\s]', '', text)
        text = text.lower()
        return ' '.join(word for word in text.split() if word not in stop_words)
    return ""

all_reviews_df['cleaned_review_text'] = all_reviews_df['review_text'].apply(clean_text)

lemmatizer = WordNetLemmatizer()

def lemmatize(text):
    tokens = nltk.word_tokenize(text, language='english')
    return " ".join(lemmatizer.lemmatize(word) for word in tokens)

all_reviews_df['lemmatized_review_text'] = all_reviews_df['cleaned_review_text'].apply(lemmatize)



nltk.download('punkt_tab')

nltk.download('punkt_tab')

tfidf = TfidfVectorizer(max_features=1000)
X = tfidf.fit_transform(all_reviews_df['lemmatized_review_text'])

from io import StringIO
import json

tags_data = """name,review,tags
Coffee Bar,"Great coffee and quiet ambience","['good-coffee', 'quiet']"
Star Cafe,"Very affordable and dog-friendly","['affordable', 'pet-friendly']"
FastBrew,"Crowded but friendly staff","['crowded', 'friendly']"
"""

tags_df = pd.read_csv(StringIO(tags_data))
tags_df['tags'] = tags_df['tags'].apply(lambda x: json.loads(x.replace("'", '"')))

reviews_sample = all_reviews_df.head(tags_df.shape[0]).copy()
reviews_sample['tags'] = tags_df['tags']

mlb = MultiLabelBinarizer()
y = mlb.fit_transform(reviews_sample['tags'])

X_demo = tfidf.transform(reviews_sample['lemmatized_review_text'])

model = OneVsRestClassifier(LogisticRegression(solver='liblinear'))
model.fit(X_demo, y)

